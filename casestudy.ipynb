{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "# Convert to a DataFrame\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['species'] = iris.target\n",
    "\n",
    "# Filter for binary classification 'versicolor' vs 'virginica' ['setosa' 'versicolor' 'virginica']\n",
    "X = iris_df[iris_df['species'].isin([1, 2])].copy()\n",
    "\n",
    "# Relabel the target column (optional: make species binary 0 and 1)\n",
    "X['species'] = X['species'].map({1: 0, 2: 1})\n",
    "\n",
    "#to array\n",
    "X = X.values\n",
    "\n",
    "# Print the filtered dataset\n",
    "X.shape # (100, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 4)\n",
      "(20, 4)\n",
      "(80, 1)\n",
      "(20, 1)\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "y_train = X_train[:, -1].reshape(-1, 1)\n",
    "y_test = X_test[:, -1].reshape(-1, 1)\n",
    "X_train = X_train[:, :-1]\n",
    "X_test = X_test[:, :-1]\n",
    "\n",
    "print(X_train.shape) # (80, 5) m examples, n features\n",
    "print(X_test.shape)  # (20, 5)\n",
    "print(y_train.shape) # (80,1)\n",
    "print(y_test.shape)  # (20,1)\n",
    "\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 4.464423400572354\n",
      "Cost after iteration 100: 0.5677639597116839\n",
      "Cost after iteration 200: 0.5372020782531204\n",
      "Cost after iteration 300: 0.5097677684246726\n",
      "Cost after iteration 400: 0.4850760988438422\n",
      "Cost after iteration 500: 0.46278836422610536\n",
      "Cost after iteration 600: 0.44260887662494613\n",
      "Cost after iteration 700: 0.4242808292625258\n",
      "Cost after iteration 800: 0.4075818609934721\n",
      "Cost after iteration 900: 0.3923197094660257\n",
      "Cost after iteration 1000: 0.37832816889600884\n",
      "Cost after iteration 1100: 0.3654634537674616\n",
      "Cost after iteration 1200: 0.35360099843395953\n",
      "Cost after iteration 1300: 0.34263268132062524\n",
      "Cost after iteration 1400: 0.3324644408436957\n",
      "Cost after iteration 1500: 0.3230142408227515\n",
      "Cost after iteration 1600: 0.31421034102645845\n",
      "Cost after iteration 1700: 0.30598983031841304\n",
      "Cost after iteration 1800: 0.2982973836436536\n",
      "Cost after iteration 1900: 0.291084208623191\n",
      "Cost after iteration 2000: 0.2843071521282195\n",
      "Cost after iteration 2100: 0.2779279415333496\n",
      "Cost after iteration 2200: 0.2719125392369639\n",
      "Cost after iteration 2300: 0.26623059243471103\n",
      "Cost after iteration 2400: 0.26085496304740374\n",
      "Cost after iteration 2500: 0.25576132517538847\n",
      "Cost after iteration 2600: 0.25092781952843984\n",
      "Cost after iteration 2700: 0.2463347560167287\n",
      "Cost after iteration 2800: 0.24196435713523534\n",
      "Cost after iteration 2900: 0.2378005359769977\n",
      "Cost after iteration 3000: 0.23382870370997294\n",
      "Cost after iteration 3100: 0.23003560218237287\n",
      "Cost after iteration 3200: 0.22640915801113115\n",
      "Cost after iteration 3300: 0.2229383550819138\n",
      "Cost after iteration 3400: 0.21961312286692689\n",
      "Cost after iteration 3500: 0.21642423836537503\n",
      "Cost after iteration 3600: 0.21336323980449168\n",
      "Cost after iteration 3700: 0.21042235051792876\n",
      "Cost after iteration 3800: 0.2075944116522339\n",
      "Cost after iteration 3900: 0.2048728225488291\n",
      "Cost after iteration 4000: 0.20225148781462052\n",
      "Cost after iteration 4100: 0.19972477023430155\n",
      "Cost after iteration 4200: 0.19728744879583715\n",
      "Cost after iteration 4300: 0.19493468120107088\n",
      "Cost after iteration 4400: 0.19266197031878873\n",
      "Cost after iteration 4500: 0.19046513411033222\n",
      "Cost after iteration 4600: 0.18834027861997865\n",
      "Cost after iteration 4700: 0.18628377367547522\n",
      "Cost after iteration 4800: 0.1842922309897086\n",
      "Cost after iteration 4900: 0.18236248439368097\n",
      "Cost after iteration 5000: 0.18049157196471363\n",
      "Cost after iteration 5100: 0.178676719842929\n",
      "Cost after iteration 5200: 0.17691532755425313\n",
      "Cost after iteration 5300: 0.17520495468000416\n",
      "Cost after iteration 5400: 0.1735433087320892\n",
      "Cost after iteration 5500: 0.1719282341093132\n",
      "Cost after iteration 5600: 0.17035770202467007\n",
      "Cost after iteration 5700: 0.16882980130603478\n",
      "Cost after iteration 5800: 0.16734272998364116\n",
      "Cost after iteration 5900: 0.16589478758734905\n",
      "Cost after iteration 6000: 0.16448436808514222\n",
      "Cost after iteration 6100: 0.1631099534017163\n",
      "Cost after iteration 6200: 0.16177010746255321\n",
      "Cost after iteration 6300: 0.1604634707146412\n",
      "Cost after iteration 6400: 0.15918875508009392\n",
      "Cost after iteration 6500: 0.1579447393034264\n",
      "Cost after iteration 6600: 0.15673026465724244\n",
      "Cost after iteration 6700: 0.1555442309746309\n",
      "Cost after iteration 6800: 0.15438559297972038\n",
      "Cost after iteration 6900: 0.15325335689064562\n",
      "Cost after iteration 7000: 0.15214657727168007\n",
      "Cost after iteration 7100: 0.15106435411351873\n",
      "Cost after iteration 7200: 0.15000583012269175\n",
      "Cost after iteration 7300: 0.14897018820287303\n",
      "Cost after iteration 7400: 0.14795664911244696\n",
      "Cost after iteration 7500: 0.1469644692841325\n",
      "Cost after iteration 7600: 0.14599293879375275\n",
      "Cost after iteration 7700: 0.14504137946639628\n",
      "Cost after iteration 7800: 0.14410914310926162\n",
      "Cost after iteration 7900: 0.1431956098614188\n",
      "Cost after iteration 8000: 0.1423001866515658\n",
      "Cost after iteration 8100: 0.14142230575563394\n",
      "Cost after iteration 8200: 0.140561423446781\n",
      "Cost after iteration 8300: 0.1397170187309469\n",
      "Cost after iteration 8400: 0.13888859216171157\n",
      "Cost after iteration 8500: 0.13807566472871471\n",
      "Cost after iteration 8600: 0.13727777681436415\n",
      "Cost after iteration 8700: 0.13649448721398919\n",
      "Cost after iteration 8800: 0.13572537221497957\n",
      "Cost after iteration 8900: 0.13497002473081024\n",
      "Cost after iteration 9000: 0.13422805348616892\n",
      "Cost after iteration 9100: 0.13349908224970172\n",
      "Cost after iteration 9200: 0.13278274911115956\n",
      "Cost after iteration 9300: 0.13207870579997447\n",
      "Cost after iteration 9400: 0.13138661704251758\n",
      "Cost after iteration 9500: 0.13070615995550214\n",
      "Cost after iteration 9600: 0.13003702347317553\n",
      "Cost after iteration 9700: 0.12937890780612588\n",
      "Cost after iteration 9800: 0.12873152392968124\n",
      "Cost after iteration 9900: 0.12809459310002852\n",
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from models.logisticregression import LogisticRegression\n",
    "from models.gradient_check import gradient_check\n",
    "\n",
    "lr_model = LogisticRegression(n_inputs=X_train.shape[0], learning_rate=0.01, n_iters=10000, lambd_reg=0.01)\n",
    "lr_model.fit(X_train, y_train)\n",
    "predictions = lr_model.predict(X_test)\n",
    "\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.713454571435081\n",
      "Cost after iteration 100: 0.693215401058475\n",
      "Cost after iteration 200: 0.6910508237842506\n",
      "Cost after iteration 300: 0.6899781103832345\n",
      "Cost after iteration 400: 0.687114724674732\n",
      "Cost after iteration 500: 0.6721527249305095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 600: 0.6545307322157097\n",
      "Cost after iteration 700: 0.6367342706778957\n",
      "Cost after iteration 800: 0.6146547992653425\n",
      "Cost after iteration 900: 0.587592521281035\n",
      "Cost after iteration 1000: 0.5557409847648224\n",
      "Cost after iteration 1100: 0.5201139347161551\n",
      "Cost after iteration 1200: 0.4823260607356068\n",
      "Cost after iteration 1300: 0.44418775541354677\n",
      "Cost after iteration 1400: 0.40729460241988086\n",
      "Cost after iteration 1500: 0.37278188495825837\n",
      "Cost after iteration 1600: 0.3412804779195105\n",
      "Cost after iteration 1700: 0.3130053688208049\n",
      "Cost after iteration 1800: 0.28788892146165396\n",
      "Cost after iteration 1900: 0.2657022915447698\n",
      "Cost after iteration 2000: 0.24614397572826152\n",
      "Cost after iteration 2100: 0.22889561443845677\n",
      "Cost after iteration 2200: 0.21365295935644626\n",
      "Cost after iteration 2300: 0.2001405446062872\n",
      "Cost after iteration 2400: 0.1881166952274514\n",
      "Cost after iteration 2500: 0.17737331215637633\n",
      "Cost after iteration 2600: 0.16773314467183761\n",
      "Cost after iteration 2700: 0.15904609368682865\n",
      "Cost after iteration 2800: 0.15118536583091413\n",
      "Cost after iteration 2900: 0.1440438759161159\n",
      "Cost after iteration 3000: 0.13753106088781492\n",
      "Cost after iteration 3100: 0.1315701450015868\n",
      "Cost after iteration 3200: 0.12609583573674882\n",
      "Cost after iteration 3300: 0.121052404264962\n",
      "Cost after iteration 3400: 0.11639209668632373\n",
      "Cost after iteration 3500: 0.11207382353112263\n",
      "Cost after iteration 3600: 0.10806208021323048\n",
      "Cost after iteration 3700: 0.10432605760121648\n",
      "Cost after iteration 3800: 0.10083890835373707\n",
      "Cost after iteration 3900: 0.09757714056684016\n",
      "Cost after iteration 4000: 0.09452011539562839\n",
      "Cost after iteration 4100: 0.09164962962018007\n",
      "Cost after iteration 4200: 0.08894956768962477\n",
      "Cost after iteration 4300: 0.08640561069464806\n",
      "Cost after iteration 4400: 0.08400499208878817\n",
      "Cost after iteration 4500: 0.08173629189706685\n",
      "Cost after iteration 4600: 0.07958926269947983\n",
      "Cost after iteration 4700: 0.07755468192653472\n",
      "Cost after iteration 4800: 0.07562422601221153\n",
      "Cost after iteration 4900: 0.07379036276362512\n",
      "Cost after iteration 5000: 0.0720462589644983\n",
      "Cost after iteration 5100: 0.0703857007620267\n",
      "Cost after iteration 5200: 0.06880302481851246\n",
      "Cost after iteration 5300: 0.06729305855999518\n",
      "Cost after iteration 5400: 0.0658510681398118\n",
      "Cost after iteration 5500: 0.06447271296822117\n",
      "Cost after iteration 5600: 0.0631540058500462\n",
      "Cost after iteration 5700: 0.061891277928818815\n",
      "Cost after iteration 5800: 0.06068114776467574\n",
      "Cost after iteration 5900: 0.059520493979455885\n",
      "Cost after iteration 6000: 0.058406430990295535\n",
      "Cost after iteration 6100: 0.05733628742590173\n",
      "Cost after iteration 6200: 0.05630758688031806\n",
      "Cost after iteration 6300: 0.05531803070961291\n",
      "Cost after iteration 6400: 0.054365482619281535\n",
      "Cost after iteration 6500: 0.05344795482573925\n",
      "Cost after iteration 6600: 0.05256359560525273\n",
      "Cost after iteration 6700: 0.05171067806898193\n",
      "Cost after iteration 6800: 0.05088759002428161\n",
      "Cost after iteration 6900: 0.05009282480066191\n",
      "Cost after iteration 7000: 0.049324972934386445\n",
      "Cost after iteration 7100: 0.04858271461900676\n",
      "Cost after iteration 7200: 0.047864812840567976\n",
      "Cost after iteration 7300: 0.04717010712606341\n",
      "Cost after iteration 7400: 0.04649750784220822\n",
      "Cost after iteration 7500: 0.04584599098895975\n",
      "Cost after iteration 7600: 0.04521459343859399\n",
      "Cost after iteration 7700: 0.04460240857670291\n",
      "Cost after iteration 7800: 0.044008582306325185\n",
      "Cost after iteration 7900: 0.04343230938066715\n",
      "Cost after iteration 8000: 0.042872830033581645\n",
      "Cost after iteration 8100: 0.04232942688024953\n",
      "Cost after iteration 8200: 0.041801422063380285\n",
      "Cost after iteration 8300: 0.041288174622794147\n",
      "Cost after iteration 8400: 0.04078907806849251\n",
      "Cost after iteration 8500: 0.04030355813931847\n",
      "Cost after iteration 8600: 0.039831070731076765\n",
      "Cost after iteration 8700: 0.039371099979556755\n",
      "Cost after iteration 8800: 0.038923156485304145\n",
      "Cost after iteration 8900: 0.03848677566824018\n",
      "Cost after iteration 9000: 0.03806151624134379\n",
      "Cost after iteration 9100: 0.0376469587936186\n",
      "Cost after iteration 9200: 0.03724270447345997\n",
      "Cost after iteration 9300: 0.03684837376434922\n",
      "Cost after iteration 9400: 0.03646360534552577\n",
      "Cost after iteration 9500: 0.036088055030939946\n",
      "Cost after iteration 9600: 0.03572139478038196\n",
      "Cost after iteration 9700: 0.03536331177721106\n",
      "Cost after iteration 9800: 0.035013507567591855\n",
      "Cost after iteration 9900: 0.03467169725657737\n",
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "from models.fnn_classifier import FNN1Layer\n",
    "# Train the model\n",
    "fnn1_model = FNN1Layer(input_dim=X_train.shape[0], output_dim=1, nunits=4, learning_rate=0.01, n_iters=10000, lambd_reg=0.01)\n",
    "parameters = fnn1_model.fit(X_train, y_train)\n",
    "predictions = fnn1_model.predict(X_test)\n",
    "\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward propagation works well! Difference = 2.1661993553863727e-08\n",
      "Cost after iteration 0: 0.6931709277292022\n",
      "Cost after iteration 100: 0.6926515835077642\n",
      "Cost after iteration 200: 0.6923430459101321\n",
      "Cost after iteration 300: 0.6921568374071031\n",
      "Cost after iteration 400: 0.6920392645784834\n",
      "Cost after iteration 500: 0.6919612103710641\n",
      "Cost after iteration 600: 0.6919041183458384\n",
      "Cost after iteration 700: 0.6918553749440478\n",
      "Cost after iteration 800: 0.6918053663749809\n",
      "Cost after iteration 900: 0.6917454314722646\n",
      "Cost after iteration 1000: 0.6916662714038216\n",
      "Cost after iteration 1100: 0.6915563000951811\n",
      "Cost after iteration 1200: 0.6913999604201397\n",
      "Cost after iteration 1300: 0.6911754958066331\n",
      "Cost after iteration 1400: 0.6908520287691463\n",
      "Cost after iteration 1500: 0.6903853910940269\n",
      "Cost after iteration 1600: 0.6897126189254683\n",
      "Cost after iteration 1700: 0.6887441974091061\n",
      "Cost after iteration 1800: 0.6873537367613628\n",
      "Cost after iteration 1900: 0.6853649574064474\n",
      "Cost after iteration 2000: 0.6825361379159637\n",
      "Cost after iteration 2100: 0.6785435765539374\n",
      "Cost after iteration 2200: 0.67297108050616\n",
      "Cost after iteration 2300: 0.665306445425749\n",
      "Cost after iteration 2400: 0.6549736120219593\n",
      "Cost after iteration 2500: 0.6413782837868938\n",
      "Cost after iteration 2600: 0.6241190910450696\n",
      "Cost after iteration 2700: 0.6030718862456774\n",
      "Cost after iteration 2800: 0.5784781256010849\n",
      "Cost after iteration 2900: 0.5512682728677356\n",
      "Cost after iteration 3000: 0.52210835708855\n",
      "Cost after iteration 3100: 0.4916104422623596\n",
      "Cost after iteration 3200: 0.46107796266247547\n",
      "Cost after iteration 3300: 0.4316727547460124\n",
      "Cost after iteration 3400: 0.40353038143358655\n",
      "Cost after iteration 3500: 0.37706130184676834\n",
      "Cost after iteration 3600: 0.35305394955469044\n",
      "Cost after iteration 3700: 0.33139494997911695\n",
      "Cost after iteration 3800: 0.311549840119613\n",
      "Cost after iteration 3900: 0.29356969228985025\n",
      "Cost after iteration 4000: 0.2772599264796872\n",
      "Cost after iteration 4100: 0.26245421202853153\n",
      "Cost after iteration 4200: 0.24900479636336723\n",
      "Cost after iteration 4300: 0.23676995925370692\n",
      "Cost after iteration 4400: 0.22553611520709813\n",
      "Cost after iteration 4500: 0.21532103611243644\n",
      "Cost after iteration 4600: 0.20596592843406542\n",
      "Cost after iteration 4700: 0.1973229730886133\n",
      "Cost after iteration 4800: 0.18932270581014302\n",
      "Cost after iteration 4900: 0.18194921439913875\n",
      "Cost after iteration 5000: 0.17518171044665357\n",
      "Cost after iteration 5100: 0.16888061044277838\n",
      "Cost after iteration 5200: 0.1629972309543131\n",
      "Cost after iteration 5300: 0.15749306191033863\n",
      "Cost after iteration 5400: 0.15233392107840338\n",
      "Cost after iteration 5500: 0.1475051309585753\n",
      "Cost after iteration 5600: 0.1429868301721626\n",
      "Cost after iteration 5700: 0.13876112159101903\n",
      "Cost after iteration 5800: 0.1347790474120475\n",
      "Cost after iteration 5900: 0.13101957362876485\n",
      "Cost after iteration 6000: 0.1274640691037702\n",
      "Cost after iteration 6100: 0.12409060709819969\n",
      "Cost after iteration 6200: 0.12088827635819559\n",
      "Cost after iteration 6300: 0.11785292685284707\n",
      "Cost after iteration 6400: 0.11497236198755531\n",
      "Cost after iteration 6500: 0.11223010988102045\n",
      "Cost after iteration 6600: 0.10961213190160457\n",
      "Cost after iteration 6700: 0.10711011872832905\n",
      "Cost after iteration 6800: 0.10471651387659037\n",
      "Cost after iteration 6900: 0.10242442673577051\n",
      "Cost after iteration 7000: 0.1002275577549115\n",
      "Cost after iteration 7100: 0.09812013380494798\n",
      "Cost after iteration 7200: 0.09609685210753126\n",
      "Cost after iteration 7300: 0.09415283140863757\n",
      "Cost after iteration 7400: 0.09228356930614147\n",
      "Cost after iteration 7500: 0.0904849048266909\n",
      "Cost after iteration 7600: 0.08875298549807283\n",
      "Cost after iteration 7700: 0.08708423828609212\n",
      "Cost after iteration 7800: 0.08547534386554695\n",
      "Cost after iteration 7900: 0.08392321377757267\n",
      "Cost after iteration 8000: 0.08242497009394809\n",
      "Cost after iteration 8100: 0.08097792726565387\n",
      "Cost after iteration 8200: 0.0795795758802222\n",
      "Cost after iteration 8300: 0.07822756809195079\n",
      "Cost after iteration 8400: 0.07691970452225881\n",
      "Cost after iteration 8500: 0.07565392245546296\n",
      "Cost after iteration 8600: 0.07442828517893195\n",
      "Cost after iteration 8700: 0.07324097233668386\n",
      "Cost after iteration 8800: 0.07209027118261192\n",
      "Cost after iteration 8900: 0.07097456863414571\n",
      "Cost after iteration 9000: 0.06989234403968544\n",
      "Cost after iteration 9100: 0.06884216258390174\n",
      "Cost after iteration 9200: 0.06782266926427065\n",
      "Cost after iteration 9300: 0.06684097852716746\n",
      "Cost after iteration 9400: 0.06589509514023706\n",
      "Cost after iteration 9500: 0.06497899489533404\n",
      "Cost after iteration 9600: 0.06408782913743988\n",
      "Cost after iteration 9700: 0.06322061006557879\n",
      "Cost after iteration 9800: 0.06237640204623828\n",
      "Cost after iteration 9900: 0.06155565270750657\n",
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "from models.fnn_classifier import FNNClassifier\n",
    "\n",
    "fnn_model = FNNClassifier(X_train.shape[0], 1, [2], [\"relu\"], learning_rate=0.01, n_iters=10000, lamdb_reg=0.001)\n",
    "fnn_model.initialize_parameters()\n",
    "gradient_check(fnn_model, X_train, y_train, epsilon=1e-7)\n",
    "parameters = fnn_model.fit(X_train, y_train)\n",
    "predictions = fnn_model.predict(X_test)\n",
    "\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
