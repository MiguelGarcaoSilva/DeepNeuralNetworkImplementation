{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "# Convert to a DataFrame\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['species'] = iris.target\n",
    "\n",
    "# Filter for binary classification 'versicolor' vs 'virginica' ['setosa' 'versicolor' 'virginica']\n",
    "X = iris_df[iris_df['species'].isin([1, 2])].copy()\n",
    "\n",
    "# Relabel the target column (optional: make species binary 0 and 1)\n",
    "X['species'] = X['species'].map({1: 0, 2: 1})\n",
    "\n",
    "#to array\n",
    "X = X.values\n",
    "\n",
    "# Print the filtered dataset\n",
    "X.shape # (100, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 4)\n",
      "(20, 4)\n",
      "(80, 1)\n",
      "(20, 1)\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "y_train = X_train[:, -1].reshape(-1, 1)\n",
    "y_test = X_test[:, -1].reshape(-1, 1)\n",
    "X_train = X_train[:, :-1]\n",
    "X_test = X_test[:, :-1]\n",
    "\n",
    "print(X_train.shape) # (80, 5) m examples, n features\n",
    "print(X_test.shape)  # (20, 5)\n",
    "print(y_train.shape) # (80,1)\n",
    "print(y_test.shape)  # (20,1)\n",
    "\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 4.464423400572354\n",
      "Cost after iteration 100: 0.5677639597116839\n",
      "Cost after iteration 200: 0.5372020782531204\n",
      "Cost after iteration 300: 0.5097677684246726\n",
      "Cost after iteration 400: 0.4850760988438422\n",
      "Cost after iteration 500: 0.46278836422610536\n",
      "Cost after iteration 600: 0.44260887662494613\n",
      "Cost after iteration 700: 0.4242808292625258\n",
      "Cost after iteration 800: 0.4075818609934721\n",
      "Cost after iteration 900: 0.3923197094660257\n",
      "Cost after iteration 1000: 0.37832816889600884\n",
      "Cost after iteration 1100: 0.3654634537674616\n",
      "Cost after iteration 1200: 0.35360099843395953\n",
      "Cost after iteration 1300: 0.34263268132062524\n",
      "Cost after iteration 1400: 0.3324644408436957\n",
      "Cost after iteration 1500: 0.3230142408227515\n",
      "Cost after iteration 1600: 0.31421034102645845\n",
      "Cost after iteration 1700: 0.30598983031841304\n",
      "Cost after iteration 1800: 0.2982973836436536\n",
      "Cost after iteration 1900: 0.291084208623191\n",
      "Cost after iteration 2000: 0.2843071521282195\n",
      "Cost after iteration 2100: 0.2779279415333496\n",
      "Cost after iteration 2200: 0.2719125392369639\n",
      "Cost after iteration 2300: 0.26623059243471103\n",
      "Cost after iteration 2400: 0.26085496304740374\n",
      "Cost after iteration 2500: 0.25576132517538847\n",
      "Cost after iteration 2600: 0.25092781952843984\n",
      "Cost after iteration 2700: 0.2463347560167287\n",
      "Cost after iteration 2800: 0.24196435713523534\n",
      "Cost after iteration 2900: 0.2378005359769977\n",
      "Cost after iteration 3000: 0.23382870370997294\n",
      "Cost after iteration 3100: 0.23003560218237287\n",
      "Cost after iteration 3200: 0.22640915801113115\n",
      "Cost after iteration 3300: 0.2229383550819138\n",
      "Cost after iteration 3400: 0.21961312286692689\n",
      "Cost after iteration 3500: 0.21642423836537503\n",
      "Cost after iteration 3600: 0.21336323980449168\n",
      "Cost after iteration 3700: 0.21042235051792876\n",
      "Cost after iteration 3800: 0.2075944116522339\n",
      "Cost after iteration 3900: 0.2048728225488291\n",
      "Cost after iteration 4000: 0.20225148781462052\n",
      "Cost after iteration 4100: 0.19972477023430155\n",
      "Cost after iteration 4200: 0.19728744879583715\n",
      "Cost after iteration 4300: 0.19493468120107088\n",
      "Cost after iteration 4400: 0.19266197031878873\n",
      "Cost after iteration 4500: 0.19046513411033222\n",
      "Cost after iteration 4600: 0.18834027861997865\n",
      "Cost after iteration 4700: 0.18628377367547522\n",
      "Cost after iteration 4800: 0.1842922309897086\n",
      "Cost after iteration 4900: 0.18236248439368097\n",
      "Cost after iteration 5000: 0.18049157196471363\n",
      "Cost after iteration 5100: 0.178676719842929\n",
      "Cost after iteration 5200: 0.17691532755425313\n",
      "Cost after iteration 5300: 0.17520495468000416\n",
      "Cost after iteration 5400: 0.1735433087320892\n",
      "Cost after iteration 5500: 0.1719282341093132\n",
      "Cost after iteration 5600: 0.17035770202467007\n",
      "Cost after iteration 5700: 0.16882980130603478\n",
      "Cost after iteration 5800: 0.16734272998364116\n",
      "Cost after iteration 5900: 0.16589478758734905\n",
      "Cost after iteration 6000: 0.16448436808514222\n",
      "Cost after iteration 6100: 0.1631099534017163\n",
      "Cost after iteration 6200: 0.16177010746255321\n",
      "Cost after iteration 6300: 0.1604634707146412\n",
      "Cost after iteration 6400: 0.15918875508009392\n",
      "Cost after iteration 6500: 0.1579447393034264\n",
      "Cost after iteration 6600: 0.15673026465724244\n",
      "Cost after iteration 6700: 0.1555442309746309\n",
      "Cost after iteration 6800: 0.15438559297972038\n",
      "Cost after iteration 6900: 0.15325335689064562\n",
      "Cost after iteration 7000: 0.15214657727168007\n",
      "Cost after iteration 7100: 0.15106435411351873\n",
      "Cost after iteration 7200: 0.15000583012269175\n",
      "Cost after iteration 7300: 0.14897018820287303\n",
      "Cost after iteration 7400: 0.14795664911244696\n",
      "Cost after iteration 7500: 0.1469644692841325\n",
      "Cost after iteration 7600: 0.14599293879375275\n",
      "Cost after iteration 7700: 0.14504137946639628\n",
      "Cost after iteration 7800: 0.14410914310926162\n",
      "Cost after iteration 7900: 0.1431956098614188\n",
      "Cost after iteration 8000: 0.1423001866515658\n",
      "Cost after iteration 8100: 0.14142230575563394\n",
      "Cost after iteration 8200: 0.140561423446781\n",
      "Cost after iteration 8300: 0.1397170187309469\n",
      "Cost after iteration 8400: 0.13888859216171157\n",
      "Cost after iteration 8500: 0.13807566472871471\n",
      "Cost after iteration 8600: 0.13727777681436415\n",
      "Cost after iteration 8700: 0.13649448721398919\n",
      "Cost after iteration 8800: 0.13572537221497957\n",
      "Cost after iteration 8900: 0.13497002473081024\n",
      "Cost after iteration 9000: 0.13422805348616892\n",
      "Cost after iteration 9100: 0.13349908224970172\n",
      "Cost after iteration 9200: 0.13278274911115956\n",
      "Cost after iteration 9300: 0.13207870579997447\n",
      "Cost after iteration 9400: 0.13138661704251758\n",
      "Cost after iteration 9500: 0.13070615995550214\n",
      "Cost after iteration 9600: 0.13003702347317553\n",
      "Cost after iteration 9700: 0.12937890780612588\n",
      "Cost after iteration 9800: 0.12873152392968124\n",
      "Cost after iteration 9900: 0.12809459310002852\n",
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from models.logisticregression import LogisticRegression\n",
    "from models.gradient_check import gradient_check\n",
    "\n",
    "lr_model = LogisticRegression(n_inputs=X_train.shape[0], learning_rate=0.01, n_iters=10000, lambd_reg=0.01)\n",
    "lr_model.fit(X_train, y_train)\n",
    "predictions = lr_model.predict(X_test)\n",
    "\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.8325786870431161\n",
      "Cost after iteration 100: 0.734366151181207\n",
      "Cost after iteration 200: 0.7845607431381211\n",
      "Cost after iteration 300: 0.7279992280731136\n",
      "Cost after iteration 400: 0.7015932140497484\n",
      "Cost after iteration 500: 0.6933572049145013\n",
      "Cost after iteration 600: 0.7182087936373779\n",
      "Cost after iteration 700: 0.7020739690196285\n",
      "Cost after iteration 800: 0.6771824589363414\n",
      "Cost after iteration 900: 0.689626659230653\n",
      "Cost after iteration 1000: 0.692348078108532\n",
      "Cost after iteration 1100: 0.692176261216331\n",
      "Cost after iteration 1200: 0.6949345001305182\n",
      "Cost after iteration 1300: 0.6942334438586978\n",
      "Cost after iteration 1400: 0.6952386482081195\n",
      "Cost after iteration 1500: 0.6915669737152019\n",
      "Cost after iteration 1600: 0.6971162536574259\n",
      "Cost after iteration 1700: 0.68894992419984\n",
      "Cost after iteration 1800: 0.6959423468591693\n",
      "Cost after iteration 1900: 0.6946590845308525\n",
      "Cost after iteration 2000: 0.6968765491585177\n",
      "Cost after iteration 2100: 0.6917241028477639\n",
      "Cost after iteration 2200: 0.6903179284573087\n",
      "Cost after iteration 2300: 0.6887232451094962\n",
      "Cost after iteration 2400: 0.6879892643569749\n",
      "Cost after iteration 2500: 0.6896736976276244\n",
      "Cost after iteration 2600: 0.6886689797040794\n",
      "Cost after iteration 2700: 0.6807808018168999\n",
      "Cost after iteration 2800: 0.6772334216600977\n",
      "Cost after iteration 2900: 0.6763115943992014\n",
      "Cost after iteration 3000: 0.6615546275906459\n",
      "Cost after iteration 3100: 0.6630395989025802\n",
      "Cost after iteration 3200: 0.6401521444376249\n",
      "Cost after iteration 3300: 0.6365483174526578\n",
      "Cost after iteration 3400: 0.6097320704265387\n",
      "Cost after iteration 3500: 0.6053084227511232\n",
      "Cost after iteration 3600: 0.5661366373883759\n",
      "Cost after iteration 3700: 0.545345415868427\n",
      "Cost after iteration 3800: 0.5145482722541019\n",
      "Cost after iteration 3900: 0.5688464627860598\n",
      "Cost after iteration 4000: 0.4868590297996984\n",
      "Cost after iteration 4100: 0.4949857443295293\n",
      "Cost after iteration 4200: 0.48993831821866246\n",
      "Cost after iteration 4300: 0.4488731977383633\n",
      "Cost after iteration 4400: 0.4462120293637301\n",
      "Cost after iteration 4500: 0.40462347140494154\n",
      "Cost after iteration 4600: 0.45217262199256336\n",
      "Cost after iteration 4700: 0.4946555362604107\n",
      "Cost after iteration 4800: 0.3838526252161828\n",
      "Cost after iteration 4900: 0.4654015485555908\n",
      "Cost after iteration 5000: 0.9488662816348867\n",
      "Cost after iteration 5100: 0.8872669081118943\n",
      "Cost after iteration 5200: 0.7165508402049028\n",
      "Cost after iteration 5300: 0.6728529881945096\n",
      "Cost after iteration 5400: 0.735719021628259\n",
      "Cost after iteration 5500: 0.7521269777438806\n",
      "Cost after iteration 5600: 0.6958500932930318\n",
      "Cost after iteration 5700: 0.6886183325096866\n",
      "Cost after iteration 5800: 0.7010612294561414\n",
      "Cost after iteration 5900: 0.6966436434219059\n",
      "Cost after iteration 6000: 0.6992348212242091\n",
      "Cost after iteration 6100: 0.6945962195726394\n",
      "Cost after iteration 6200: 0.6888347740710333\n",
      "Cost after iteration 6300: 0.6993615371450059\n",
      "Cost after iteration 6400: 0.6911727069210847\n",
      "Cost after iteration 6500: 0.6887065265051475\n",
      "Cost after iteration 6600: 0.6842230038547936\n",
      "Cost after iteration 6700: 0.6930631617166967\n",
      "Cost after iteration 6800: 0.6925992940111086\n",
      "Cost after iteration 6900: 0.693187996488242\n",
      "Cost after iteration 7000: 0.6881504856664381\n",
      "Cost after iteration 7100: 0.6973706203041691\n",
      "Cost after iteration 7200: 0.6939513163669739\n",
      "Cost after iteration 7300: 0.689333461684502\n",
      "Cost after iteration 7400: 0.6924366529184345\n",
      "Cost after iteration 7500: 0.692167070086261\n",
      "Cost after iteration 7600: 0.6961842058737094\n",
      "Cost after iteration 7700: 0.6895062526972606\n",
      "Cost after iteration 7800: 0.6981981256723021\n",
      "Cost after iteration 7900: 0.6957474831332959\n",
      "Cost after iteration 8000: 0.6921648167896743\n",
      "Cost after iteration 8100: 0.6930256164811177\n",
      "Cost after iteration 8200: 0.69141260723474\n",
      "Cost after iteration 8300: 0.6933159628553609\n",
      "Cost after iteration 8400: 0.6895665551947158\n",
      "Cost after iteration 8500: 0.6911561696186898\n",
      "Cost after iteration 8600: 0.6906211485198619\n",
      "Cost after iteration 8700: 0.6903512850287353\n",
      "Cost after iteration 8800: 0.6922424620234199\n",
      "Cost after iteration 8900: 0.6947556439366995\n",
      "Cost after iteration 9000: 0.6915663327294802\n",
      "Cost after iteration 9100: 0.6929327272982736\n",
      "Cost after iteration 9200: 0.6920887125163081\n",
      "Cost after iteration 9300: 0.6922450876982587\n",
      "Cost after iteration 9400: 0.6909080859977595\n",
      "Cost after iteration 9500: 0.6915942129877731\n",
      "Cost after iteration 9600: 0.6929131817904646\n",
      "Cost after iteration 9700: 0.6931753760345767\n",
      "Cost after iteration 9800: 0.6938721820419076\n",
      "Cost after iteration 9900: 0.6930401485586091\n",
      "Accuracy: 0.4\n"
     ]
    }
   ],
   "source": [
    "from models.fnn_classifier import FNN1Layer\n",
    "# Train the model\n",
    "fnn1_model = FNN1Layer(input_dim=X_train.shape[0], output_dim=1, nunits=4, learning_rate=0.01, n_iters=10000, lambd_reg=0.00, dropout=0.1)\n",
    "parameters = fnn1_model.fit(X_train, y_train)\n",
    "predictions = fnn1_model.predict(X_test)\n",
    "\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward propagation works well! Difference = 2.1661993553863727e-08\n",
      "Cost after iteration 0: 0.6931709277292022\n",
      "Cost after iteration 100: 0.6926515835077642\n",
      "Cost after iteration 200: 0.6923430459101321\n",
      "Cost after iteration 300: 0.6921568374071031\n",
      "Cost after iteration 400: 0.6920392645784834\n",
      "Cost after iteration 500: 0.6919612103710641\n",
      "Cost after iteration 600: 0.6919041183458384\n",
      "Cost after iteration 700: 0.6918553749440478\n",
      "Cost after iteration 800: 0.6918053663749809\n",
      "Cost after iteration 900: 0.6917454314722646\n",
      "Cost after iteration 1000: 0.6916662714038216\n",
      "Cost after iteration 1100: 0.6915563000951811\n",
      "Cost after iteration 1200: 0.6913999604201397\n",
      "Cost after iteration 1300: 0.6911754958066331\n",
      "Cost after iteration 1400: 0.6908520287691463\n",
      "Cost after iteration 1500: 0.6903853910940269\n",
      "Cost after iteration 1600: 0.6897126189254683\n",
      "Cost after iteration 1700: 0.6887441974091061\n",
      "Cost after iteration 1800: 0.6873537367613628\n",
      "Cost after iteration 1900: 0.6853649574064474\n",
      "Cost after iteration 2000: 0.6825361379159637\n",
      "Cost after iteration 2100: 0.6785435765539374\n",
      "Cost after iteration 2200: 0.67297108050616\n",
      "Cost after iteration 2300: 0.665306445425749\n",
      "Cost after iteration 2400: 0.6549736120219593\n",
      "Cost after iteration 2500: 0.6413782837868938\n",
      "Cost after iteration 2600: 0.6241190910450696\n",
      "Cost after iteration 2700: 0.6030718862456774\n",
      "Cost after iteration 2800: 0.5784781256010849\n",
      "Cost after iteration 2900: 0.5512682728677356\n",
      "Cost after iteration 3000: 0.52210835708855\n",
      "Cost after iteration 3100: 0.4916104422623596\n",
      "Cost after iteration 3200: 0.46107796266247547\n",
      "Cost after iteration 3300: 0.4316727547460124\n",
      "Cost after iteration 3400: 0.40353038143358655\n",
      "Cost after iteration 3500: 0.37706130184676834\n",
      "Cost after iteration 3600: 0.35305394955469044\n",
      "Cost after iteration 3700: 0.33139494997911695\n",
      "Cost after iteration 3800: 0.311549840119613\n",
      "Cost after iteration 3900: 0.29356969228985025\n",
      "Cost after iteration 4000: 0.2772599264796872\n",
      "Cost after iteration 4100: 0.26245421202853153\n",
      "Cost after iteration 4200: 0.24900479636336723\n",
      "Cost after iteration 4300: 0.23676995925370692\n",
      "Cost after iteration 4400: 0.22553611520709813\n",
      "Cost after iteration 4500: 0.21532103611243644\n",
      "Cost after iteration 4600: 0.20596592843406542\n",
      "Cost after iteration 4700: 0.1973229730886133\n",
      "Cost after iteration 4800: 0.18932270581014302\n",
      "Cost after iteration 4900: 0.18194921439913875\n",
      "Cost after iteration 5000: 0.17518171044665357\n",
      "Cost after iteration 5100: 0.16888061044277838\n",
      "Cost after iteration 5200: 0.1629972309543131\n",
      "Cost after iteration 5300: 0.15749306191033863\n",
      "Cost after iteration 5400: 0.15233392107840338\n",
      "Cost after iteration 5500: 0.1475051309585753\n",
      "Cost after iteration 5600: 0.1429868301721626\n",
      "Cost after iteration 5700: 0.13876112159101903\n",
      "Cost after iteration 5800: 0.1347790474120475\n",
      "Cost after iteration 5900: 0.13101957362876485\n",
      "Cost after iteration 6000: 0.1274640691037702\n",
      "Cost after iteration 6100: 0.12409060709819969\n",
      "Cost after iteration 6200: 0.12088827635819559\n",
      "Cost after iteration 6300: 0.11785292685284707\n",
      "Cost after iteration 6400: 0.11497236198755531\n",
      "Cost after iteration 6500: 0.11223010988102045\n",
      "Cost after iteration 6600: 0.10961213190160457\n",
      "Cost after iteration 6700: 0.10711011872832905\n",
      "Cost after iteration 6800: 0.10471651387659037\n",
      "Cost after iteration 6900: 0.10242442673577051\n",
      "Cost after iteration 7000: 0.1002275577549115\n",
      "Cost after iteration 7100: 0.09812013380494798\n",
      "Cost after iteration 7200: 0.09609685210753126\n",
      "Cost after iteration 7300: 0.09415283140863757\n",
      "Cost after iteration 7400: 0.09228356930614147\n",
      "Cost after iteration 7500: 0.0904849048266909\n",
      "Cost after iteration 7600: 0.08875298549807283\n",
      "Cost after iteration 7700: 0.08708423828609212\n",
      "Cost after iteration 7800: 0.08547534386554695\n",
      "Cost after iteration 7900: 0.08392321377757267\n",
      "Cost after iteration 8000: 0.08242497009394809\n",
      "Cost after iteration 8100: 0.08097792726565387\n",
      "Cost after iteration 8200: 0.0795795758802222\n",
      "Cost after iteration 8300: 0.07822756809195079\n",
      "Cost after iteration 8400: 0.07691970452225881\n",
      "Cost after iteration 8500: 0.07565392245546296\n",
      "Cost after iteration 8600: 0.07442828517893195\n",
      "Cost after iteration 8700: 0.07324097233668386\n",
      "Cost after iteration 8800: 0.07209027118261192\n",
      "Cost after iteration 8900: 0.07097456863414571\n",
      "Cost after iteration 9000: 0.06989234403968544\n",
      "Cost after iteration 9100: 0.06884216258390174\n",
      "Cost after iteration 9200: 0.06782266926427065\n",
      "Cost after iteration 9300: 0.06684097852716746\n",
      "Cost after iteration 9400: 0.06589509514023706\n",
      "Cost after iteration 9500: 0.06497899489533404\n",
      "Cost after iteration 9600: 0.06408782913743988\n",
      "Cost after iteration 9700: 0.06322061006557879\n",
      "Cost after iteration 9800: 0.06237640204623828\n",
      "Cost after iteration 9900: 0.06155565270750657\n",
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "from models.fnn_classifier import FNNClassifier\n",
    "\n",
    "fnn_model = FNNClassifier(X_train.shape[0], 1, [2], [\"relu\"], learning_rate=0.01, n_iters=10000, lamdb_reg=0.001)\n",
    "fnn_model.initialize_parameters()\n",
    "gradient_check(fnn_model, X_train, y_train, epsilon=1e-7)\n",
    "parameters = fnn_model.fit(X_train, y_train)\n",
    "predictions = fnn_model.predict(X_test)\n",
    "\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
